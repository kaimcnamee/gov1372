---
title: "final-1-1"
author: "Kai McNamee"
date: "11/17/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(estimatr)
library(haven)
library(stargazer)
library(lubridate)
library(sjlabelled)
library(latticeExtra)
library(gtrendsR)
library(janitor)
library(dotwhisker)

# Mapping
library(tidycensus)
library(sf)
```

```{r read-data message=FALSE}
### Nationscape data
# Collect the file names and select which ones we want

file_names_1 <- list.files("data/Nationscape-DataRelease_WeeklyMaterials_DTA/phase_1_v20200814/") %>% .[1:24]
file_names_2 <- list.files("data/Nationscape-DataRelease_WeeklyMaterials_DTA/phase_2_v20200814/") %>% .[1:26]

# Reading in all phase 1 and 2 weeks

phase_1 <- map_dfr(.x = file_names_1, 
                   ~read_dta(file = str_c("data/Nationscape-DataRelease_WeeklyMaterials_DTA/phase_1_v20200814/", ., "/", ., ".dta")) %>% 
                     remove_all_labels()) %>%   
  mutate(across(.cols = everything(), ~na_if(., 999))) %>% 
  mutate(across(.cols = everything(), ~na_if(., 888)))

phase_2 <- map_dfr(.x = file_names_2, 
                   ~read_dta(file = str_c("data/Nationscape-DataRelease_WeeklyMaterials_DTA/phase_2_v20200814/", ., "/", ., ".dta")) %>% 
                     remove_all_labels()) %>%   
  mutate(across(.cols = everything(), ~na_if(., 999))) %>% 
  mutate(across(.cols = everything(), ~na_if(., 888)))

# Join phase 1 and 2

ns_joined <- full_join(phase_1, phase_2)

# Select variables

ns_vars <- c(party = "pid3", 
             gender = "gender",
             race = "race_ethnicity",
             state = "state",
             fox = "news_sources_fox",
             cnn = "news_sources_cnn",
             asians = "group_favorability_asians")

ns_selected <- ns_joined %>% 
  select(response_id, start_date, ns_vars) %>% 
  mutate(party = case_when(party == 1 ~ "Democrat",
                           party == 2 ~ "Republican",
                           party == 3 ~ "Independent",
                           T ~ NA_character_),
         fox = ifelse(fox == 1, TRUE, FALSE),
         cnn = ifelse(cnn == 1, TRUE, FALSE),
         start_date = as_date(start_date)) %>% 
  rename(date = start_date)

### Covid data
# Read covid data from
# https://data.cdc.gov/Case-Surveillance/United-States-COVID-19-Cases-and-Deaths-by-State-o/9mfq-cb36

covid_states <- read_csv("data/United_States_COVID-19_Cases_and_Deaths_by_State_over_Time.csv", 
                         col_types = cols(.default = col_guess())) %>% 
  rename(date = submission_date) %>%
  mutate(date = as_date(mdy(date))) %>% 
  filter(date < as_date("2020-08-01)")) %>% 
  select(date, state, tot_cases, new_case, tot_death, new_death)

### Lockdown data
# Read lockdown data from https://www.nytimes.com/interactive/2020/us/coronavirus-stay-at-home-order.html

lockdowns <- read_csv("data/nyt_stay_at_home.csv", col_types = cols(.default = col_guess())) %>% 
  select(Abbreviation, Date) %>% 
  rename(start_date = Date, state = Abbreviation) %>% 
  mutate(start_date = as_date(mdy(start_date)))

### Gtrends data
## NOTE: gtrends() calls take a long time so the outputs are saved as RDS files

# Read in Google trends data related to the pandemic

# keywords = c("china virus", "china", "covid", "coronavirus")
# 
# gtrends <- gtrends(keyword = keywords,
#                    geo = "US",
#                    gprop = "web",
#                    time = "2020-01-22 2020-07-02")
# 
# saveRDS(gtrends, "data/gtrends.RDS")

gtrends <- readRDS("data/gtrends.RDS") 

# search_coronavirus <- gtrends(keyword = "coronavirus",
#                               geo = "US",
#                               gprop = "web",
#                               time = "2020-01-22 2020-07-02")
# 
# search_coronavirus <- search_coronavirus$interest_over_time
#   
# saveRDS(search_coronavirus, "data/search_coronavirus.RDS")

search_coronavirus <- readRDS("data/search_coronavirus.RDS") %>% 
  mutate(hits = as.numeric(replace(hits, hits == "<1", 0)))

# search_covid <- gtrends(keyword = "covid",
#                         geo = "US",
#                         gprop = "web",
#                         time = "2020-01-22 2020-07-02")
# 
# search_covid <- search_covid$interest_over_time
# 
# saveRDS(search_covid, "data/search_covid.RDS")

search_covid <- readRDS("data/search_covid.RDS") %>% 
  mutate(hits = as.numeric(replace(hits, hits == "<1", 0)))
  
# trends time series (NOTE: gtrends() call with multiple keywords will return
# hits relative to the other terms)

search_time <- gtrends$interest_over_time %>% 
  mutate(hits = as.numeric(replace(hits, hits == "<1", 0))) %>% 
  pivot_wider(names_from = keyword, values_from = hits) %>% 
  clean_names() %>% 
  select(-(geo:category))

# For state data over time, call the gtrends function for every 2 day pair in
# the date range.

# dates <- tibble(date_pair = paste(seq(as_date("2020-01-22"), as_date("2020-07-02"), "days"), 
#                                    seq(as_date("2020-01-23"), as_date("2020-07-03"), "days"))) %>% 
#   mutate(call_group = row_number())
# 
# # search_state <- map(.x = dates$date_pair, ~gtrends(keyword = keywords, geo = "US", gprop = "web", time = as_character(.)))
# # saveRDS(search_state, "gtrends_state.RDS")
# 
# # Unnest the list object gtrends() outputs
# 
# search_state <- map_dfr(.x = seq(1, 163, 1), ~search_state[[.]]$interest_by_region)
# 
# # Clean the data and match calls with dates
# 
# search_state_clean <- search_state %>%
#   mutate(call_group = rep(seq(1, 163, 1), each = 204)) %>% 
#   group_by(call_group) %>% 
#   pivot_wider(names_from = keyword, values_from = hits) %>% 
#   clean_names() %>% 
#   left_join(dates, by = "call_group") %>% 
#   separate(col = date_pair, into = c("start_date", "end_date"), sep = "\\s") %>% 
#   mutate(date = as_date(start_date),
#          end_date = as_date(end_date)) %>% 
#   select(-start_date, -end_date)
# 
# # Join search_sate_clean with state abbreviations so it can be joined with
# # joined_data
#
state_abbreviations <- tibble(location = state.name) %>%
   bind_cols(tibble(state = state.abb)) %>%
   bind_rows(tibble(location = "District of Columbia", state = "DC"))
# 
# search_state_clean <- search_state_clean %>%
#   left_join(state_abbreviations, by = "location") 

# saveRDS(search_state_clean, "data/search_state_clean.RDS")

search_state_clean <- readRDS("data/search_state_clean.RDS")
```

```{r dual-axis}
# Compare trends in attitudes towards asians and covid cases

cutoff <- as_date("2020-07-01")

ns_month <- ns_selected %>% 
  mutate(month_year = as_date(my(paste0(month(date), "-", year(date))))) %>% 
  select(month_year, asians) %>% 
  drop_na() %>% 
  group_by(month_year) %>%
  summarize(asians = mean(asians), .groups = "drop") %>% 
  filter(month_year < cutoff)
  # ggplot(aes(x = month_year, y = asians)) +
  #   geom_point()

covid_month <- covid_states %>% 
  mutate(month_year = as_date(my(paste0(month(date), "-", year(date))))) %>% 
  select(month_year, tot_cases) %>% 
  group_by(month_year) %>% 
  summarize(tot_cases = sum(tot_cases), .groups = "drop") %>% 
  filter(month_year < cutoff)
  # ggplot(aes(x = month_year, y = tot_cases)) +
  #   geom_point()

obj1 <- xyplot(asians ~ month_year, data = ns_month, typ = "l", lwd = 2, col="red")
obj2 <- xyplot(tot_cases ~ month_year, data = covid_month, typ = "l", lwd = 2, col="blue")
doubleYScale(obj1, obj2, add.ylab2 = TRUE, use.style=FALSE )


ns_month
covid_month
```

```{r clean}
joined_data <- ns_selected %>% 
  mutate(race = case_when(race == 1 ~ "white", 
                          race == 2 ~ "black",
                          race == 3 ~ "american_indian",
                          race %in% seq(4, 10, 1) ~ "asian",
                          race %in% c(11, 12, 13, 14) ~ "pacific_islander",
                          race == 15 ~ "other")) %>% 
  
  
  # Join observations with state-level covid data
  
  left_join(covid_states %>% 
              rename(state_tot_cases = tot_cases,
                     state_new_case = new_case, 
                     state_tot_death = tot_death,
                     state_new_death = new_death), by = c("date", "state")) %>% 
  
  # Join observations with national covid data (group by date and sum cases
  # before join)
  
  left_join(covid_states %>% 
              group_by(date) %>% 
              summarize(tot_cases = sum(tot_cases),
                        new_case = sum(new_case),
                        tot_death = sum(tot_death),
                        new_death = sum(new_death),
                        .groups = "drop"), 
            by = "date") %>% 
  # mutate(tot_cases = ifelse(is.na(tot_cases) == TRUE, 0, tot_cases)) %>% 
  
  # Join lockdown data. 
  
  left_join(lockdowns, by = "state") %>% 
    
  # For case_when: 
  # 1. code lockdown as NA if the observation is before the pandemic started (ie when tot_cases == NA)
  # 2. code lockdown as FALSE if the respondent's state never implemented a
  #     lockdown (ie when tot_cases =/= NA, but lockdown start_date == NA)
  # 3. code lockdown as FALSE if the response is before the respondent's state
  #     implmented a lockdown (ie when tot_cases =/= NA, and lockdown start_date =/=
  #     NA)
  # 4. otherwise, code lockdown as TRUE (ie when tot_cases =/= NA, lockdown
  #     start_date =/= NA, and response date is after lockdown start_date)
  
  mutate(lockdown = case_when(is.na(tot_cases) == TRUE ~ NA, 
                              is.na(start_date) == TRUE ~ FALSE, 
                              date < start_date ~ FALSE,
                              T ~ TRUE)) %>% 
  
  # Join state-level covid search data
  
  left_join(search_state_clean, by = c("state", "date")) %>% 
  rename(search_china_virus = china_virus,
         search_china = china,
         search_covid = covid, 
         search_coronavirus = coronavirus) %>% 
  select(-c(geo, gprop, call_group)) %>% 
  drop_na(asians) %>% 
  
  # Join national covid search data
  
  left_join(search_coronavirus %>% 
              rename(us_search_coronavirus = hits) %>% 
              select(date, us_search_coronavirus), by = "date") %>% 
  
  left_join(search_covid %>% 
              rename(us_search_covid = hits) %>% 
              select(date, us_search_covid), by = "date")

saveRDS(joined_data, "data/joined_data.RDS")

covid_date <- covid_states %>%
  group_by(date) %>%
  summarize(tot_cases = sum(tot_cases), .groups = "drop")
```


```{r cases-viz}
# ns_selected %>% 
#   drop_na() %>% 
#   group_by(date) %>% 
#   summarize(asians = mean(asians), .groups = "drop") %>% 
#   left_join(covid_states %>% 
#               group_by(date) %>% 
#               summarize(tot_cases = sum(tot_cases), .groups = "drop"), 
#             by = "date") %>% 
#   filter(date >= as_date("2020-01-22"))
  

# group_favorability_asians plot

joined_data %>%
  drop_na(asians) %>%
  group_by(date) %>%
  summarize(asians = mean(asians),
            tot_cases = mean(tot_cases), .groups = "drop") %>%
  ggplot(aes(x = as_date(date), y = asians)) +
    geom_point(color = "#f8766d") +
    geom_smooth(color = "#f8766d", method = "lm", formula = y ~ x) +
    theme_minimal() +
    labs(title = "Favorability towards Asians over time",
         x = "", y = "Favorability towards Asians") +
    scale_x_date(date_labels = "%B-%Y")

# tot_cases plot

joined_data %>%
  drop_na(tot_cases) %>%
  group_by(date) %>%
  summarize(asians = mean(asians),
            tot_cases = mean(tot_cases), .groups = "drop") %>%
  ggplot(aes(x = as_date(date), y = tot_cases)) +
    geom_point(color = "#00bfc4") +
    theme_minimal() +
    labs(title = "Total COVID cases over time",
         x = "", y = "Total COVID cases") +
  scale_x_date(date_labels = "%b-%Y")

labels <- c("asians" = "Favorability towards Asians", 
            "tot_cases" = "Total cases")

# joined_data %>% 
#   drop_na(asians, tot_cases) %>% 
#   group_by(date) %>% 
#   summarize(asians = mean(asians),
#             tot_cases = mean(tot_cases), .groups = "drop") %>% 
#   pivot_longer(cols = c(asians, tot_cases), names_to = "series", values_to = "values") %>% 
#   ggplot(aes(x = date, y = values, color = series)) +
#     geom_point(size = 0.5) +
#     facet_wrap("series", scales = "free_y", labeller = as_labeller(labels)) +
#     # scale_x_date(date_labels = "%b-%Y") +
#     scale_color_discrete(labels = as_labeller(labels), name = "") +
#     theme_minimal() +
#     theme(axis.text.x = element_text(angle = 45, vjust = 0.5)) +
#     labs(title = "", x = "", y = "") 

joined_data %>% 
  drop_na(asians, tot_cases) %>% 
  group_by(date, race) %>% 
  summarize(asians = mean(asians),
            tot_cases = mean(tot_cases), .groups = "drop") %>% 
  ggplot(aes(x = tot_cases, y = asians, color = race)) +
    geom_point(size = 0.5, alpha = 0.75) +
    geom_smooth(method = "lm") +
    theme_minimal() +
    labs(title = "Favorability towards Asians and COVID cases", 
         x = "Total US COVID cases", 
         y = "Favorability towards Asians") +
    facet_wrap("race")

```
```{r gtrends-viz}
search_state_clean %>% 
  pivot_longer(cols = c("china_virus", "china", "covid", "coronavirus"),
               names_to = "keyword", values_to = "hits") %>% 
  filter(keyword == "coronavirus") %>% 
  ggplot(aes(x = date, y = hits, color = state)) +
    geom_line() +
    facet_wrap("state")

# Visualization with state level covid search trends

joined_data %>% 
  pivot_longer(cols = c(search_china_virus, search_china, search_covid, search_coronavirus), 
               names_to = "keyword", values_to = "hits") %>% 
  group_by(keyword, hits) %>% 
  summarize(asians = mean(asians), .groups = "drop") %>% 
  filter(keyword %in% c("search_coronavirus", "search_covid")) %>% 
  ggplot(aes(x = hits, y = asians, color = keyword)) +
    geom_point(size = 0.5, alpha = 0.5) +
    geom_smooth(method = "lm", se = F) +
    facet_wrap("keyword") +
    scale_color_discrete(labels = 
                           as_labeller(c("search_coronavirus" = "Coronavirus",
                                         "search_covid" = "COVID")), 
                         name = "") +
    theme_minimal()

# Visualization with country-level covid search trends

joined_data %>% 
  drop_na(date, us_search_coronavirus, us_search_covid) %>% 
  group_by(date, us_search_coronavirus, us_search_covid) %>% 
  summarize(asians = mean(asians), .groups = "drop") %>% 
  pivot_longer(cols = c(us_search_coronavirus, us_search_covid), 
               names_to = "keyword",
               values_to = "hits") %>% 
  ggplot(aes(x = hits, y = asians, color = keyword)) +
  geom_point(size = 0.5, alpha = 0.5) +
    geom_smooth(formula = y ~ x, method = "lm", se = F) +
    theme_minimal() +
    scale_color_discrete(labels = as_labeller(
      c("us_search_coronavirus" = "Coronavirus", "us_search_covid" = "COVID"))) +
    facet_wrap("keyword", labeller = as_labeller(
      c("us_search_coronavirus" = "Coronavirus", "us_search_covid" = "COVID")))
```


```{r gtrends-map}
state_geometry <- get_acs(geography = "state",
                        variables = "B01001_001",
                        year = 2017,
                        geometry = TRUE,
                        shift_geo = TRUE,
                        summary_var = "B01001_001") %>% 
  st_transform(crs = 4326) %>% 
  clean_names() %>% 
  left_join(state_abbreviations, by = c("name" = "location")) %>% 
  select(state, geometry)

joined_geometry <- joined_data %>%
  drop_na(asians, search_coronavirus, search_china, search_china_virus, 
          search_covid) %>% 
  group_by(state) %>% 
  summarize(asians = mean(asians),
            search_coronavirus = mean(search_coronavirus), 
            search_china = mean(search_china),
            search_china_virus = mean(search_china_virus),
            search_covid = mean(search_covid), .groups = "drop") %>% 
  left_join(state_geometry, by = "state")

joined_geometry %>% 
  ggplot(aes(fill = asians, geometry = geometry)) +
    geom_sf(size = 0.5, 
            color = ifelse(joined_geometry$state %in% c("AK", "HI"), NA, "white")) +
    theme_void() + 
    theme(legend.position = "bottom") 

joined_geometry %>% 
  ggplot(aes(fill = search_covid, geometry = geometry)) +
    geom_sf(size = 0.5, 
            color = ifelse(joined_geometry$state %in% c("AK", "HI"), NA, "white")) +
    theme_void() + 
    theme(legend.position = "bottom") 

joined_geometry %>% 
  ggplot(aes(fill = search_coronavirus, geometry = geometry)) +
    geom_sf(size = 0.5, 
            color = ifelse(joined_geometry$state %in% c("AK", "HI"), NA, "white")) +
    theme_void() + 
    theme(legend.position = "bottom") 

joined_geometry %>% 
  ggplot(aes(fill = search_china, geometry = geometry)) +
    geom_sf(size = 0.5, 
            color = ifelse(joined_geometry$state %in% c("AK", "HI"), NA, "white")) +
    theme_void() + 
    theme(legend.position = "bottom") 

joined_geometry %>% 
  ggplot(aes(fill = search_china_virus, geometry = geometry)) +
    geom_sf(size = 0.5, 
            color = ifelse(joined_geometry$state %in% c("AK", "HI"), NA, "white")) +
    theme_void() + 
    theme(legend.position = "bottom") 
```




```{r models}
m1_states <- lm(asians ~ fox + cnn + party + race + date + tot_cases + new_case + tot_death + new_death + state + lockdown + search_coronavirus + search_china_virus, joined_data %>% drop_na(tot_cases))

m1 <- lm(asians ~ fox + cnn + party + race + date + tot_cases + new_case + tot_death + new_death + lockdown + search_coronavirus + search_china_virus, joined_data %>% drop_na(tot_cases))

summary(m1)

m_totals <- lm(asians ~ date + tot_cases + tot_death + lockdown, joined_data %>% drop_na(tot_cases))

m_new <- lm(asians ~ date + new_case + new_death + lockdown, joined_data %>% drop_na(tot_cases))

m_search <- lm(asians ~ search_china + search_covid + search_coronavirus + search_china_virus, joined_data %>% drop_na(tot_cases))


m4 <- lm(asians ~ date + party + cnn + fox, joined_data %>% drop_na(tot_cases))

summary(m4)


m5 <- lm(asians ~ date + party + tot_cases + tot_death + lockdown + 
           us_search_coronavirus + us_search_covid, 
         joined_data %>% drop_na(tot_cases))

m6 <- lm(asians ~ us_search_coronavirus + us_search_covid, 
         joined_data %>% drop_na(tot_cases))

stargazer(m1, m_totals, m_new, m5, type = "text")

dwplot(m6) +
  theme_minimal()
```



